{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, Subset\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import fbeta_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models = torchvision.models.list_models()\n",
    "classification_models = torchvision.models.list_models(module=torchvision.models)\n",
    "# print(f\"all models: \\n {all_models}\")\n",
    "print(f\"classif models: \\n {classification_models}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet & DenseNet\n",
    "# transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "# ])\n",
    "\n",
    "# EfficientNet_b1\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(240),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/train_classes.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tags = set()\n",
    "for tags in df['tags'].str.split():\n",
    "    all_tags.update(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_to_idx = {tag: idx for idx, tag in enumerate(sorted(all_tags))}\n",
    "idx_to_tag = {idx: tag for tag, idx in tag_to_idx.items()}\n",
    "print(tag_to_idx)\n",
    "print(len(tag_to_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiLabelImageDataset(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, transform=None):\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.df.iloc[idx, 0]\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_name}.jpg\")\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        tags = self.df.iloc[idx, 1].split()\n",
    "        labels = torch.zeros(len(tag_to_idx))\n",
    "        for tag in tags:\n",
    "            labels[tag_to_idx[tag]] = 1\n",
    "        \n",
    "        return image, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(dataset, idx):\n",
    "    image, labels = dataset[idx]\n",
    "    \n",
    "    # convert the image tensor to a PIL Image for display\n",
    "    if isinstance(image, torch.Tensor):\n",
    "        image = transforms.ToPILImage()(image)\n",
    "    \n",
    "    # plot the image\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # get the labels\n",
    "    present_labels = [idx_to_tag[i] for i, label in enumerate(labels) if label == 1]\n",
    "    \n",
    "    # set the title with the labels\n",
    "    plt.title(f\"Labels: {', '.join(present_labels)}\")\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Image labels: {', '.join(present_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MultiLabelImageDataset(csv_file=\"data/train_classes.csv\", img_dir=\"data/train-jpg\", transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_sample(dataset, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_idx, test_idx = train_test_split(list(range(len(dataset))), test_size=0.1, random_state=42)\n",
    "\n",
    "train_dataset = Subset(dataset, train_idx)\n",
    "test_dataset = Subset(dataset, test_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from torch import nn\n",
    "\n",
    "num_classes = 17\n",
    "\n",
    "def ResNetClassifier(num_classes):\n",
    "    # load a pre-trained model\n",
    "    model_ft = models.resnet50(weights='DEFAULT')\n",
    "    num_ftrs = model_ft.fc.in_features\n",
    "    \n",
    "    # freeze all the parameters in the network except the final layer\n",
    "    # for param in model_ft.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # replace the last fully connected layer\n",
    "    model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "    return model_ft\n",
    "\n",
    "def DenseNetClassifier(num_classes):\n",
    "    # load a pre-trained model\n",
    "    model_ft = models.densenet121(weights='DEFAULT')\n",
    "    num_ftrs = model_ft.classifier.in_features\n",
    "    \n",
    "    # freeze all the parameters in the network except the final layer\n",
    "    # for param in model_ft.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # replace the last fully connected layer\n",
    "    model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "    return model_ft\n",
    "\n",
    "def EfficientNetClassifier(num_classes):\n",
    "    # load a pre-trained model\n",
    "    model_ft = models.efficientnet_b1(weights='DEFAULT')\n",
    "    # num_ftrs = model_ft.classifier.in_features\n",
    "    \n",
    "    # freeze all the parameters in the network except the final layer\n",
    "    # for param in model_ft.parameters():\n",
    "    #     param.requires_grad = False\n",
    "    \n",
    "    # replace the last fully connected layer\n",
    "    model_ft.classifier = nn.Linear(1280, num_classes)\n",
    "    return model_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ResNetClassifier(num_classes)\n",
    "# model = DenseNetClassifier(num_classes)\n",
    "model = EfficientNetClassifier(num_classes)\n",
    "\n",
    "model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 64 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "\n",
    "\n",
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, f2 = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "\n",
    "            # calculate f2 score\n",
    "            pred_tags = torch.sigmoid(pred).cpu().numpy() > 0.24\n",
    "            true_tags = y.cpu().numpy()\n",
    "            f2 += fbeta_score(true_tags, pred_tags, beta=2, average='micro')\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    f2 /= num_batches\n",
    "    \n",
    "    print(f\"Test Error: \\n f2 score: {f2:.5f}, avg loss: {test_loss:>8f} \\n\")\n",
    "    return f2, test_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "all_loss = []\n",
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    f2, test_loss = test_loop(test_dataloader, model, loss_fn)\n",
    "    all_loss.append(test_loss)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_loss)\n",
    "\n",
    "epochs_list = list(range(1, len(all_loss) + 1))\n",
    "# print(len(all_loss))\n",
    "# print(epochs)\n",
    "\n",
    "plt.plot(epochs_list, all_loss, marker='o', color='b', label='Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path, transform, idx_to_tag):\n",
    "    model.eval()\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        probabilities = torch.sigmoid(outputs)\n",
    "        predicted = probabilities > 0.24\n",
    "        predicted_labels = [idx_to_tag[i] for i, pred in enumerate(predicted[0]) if pred]\n",
    "\n",
    "    return predicted_labels, probabilities[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"data/test-jpg/test_5689.jpg\"\n",
    "predicted_labels, probabilities = predict_image(model, image_path, transform, idx_to_tag)\n",
    "\n",
    "print(\"Predicted labels:\", predicted_labels)\n",
    "print(\"Probabilities:\")\n",
    "for i, prob in enumerate(probabilities):\n",
    "    if prob > 0.24:\n",
    "        print(f\"{idx_to_tag[i]}: {prob.item():.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
